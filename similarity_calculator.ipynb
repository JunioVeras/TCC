{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49c9b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junio/.local/lib/python3.10/site-packages/open_clip/factory.py:388: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models, transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import open_clip\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "model.eval()\n",
    "\n",
    "# Garante que está usando CUDA se disponível\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "def get_clip_embedding(img_path):\n",
    "    image = preprocess(Image.open(img_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.encode_image(image).squeeze().cpu().numpy()\n",
    "    return embedding\n",
    "\n",
    "def get_clip_text_embedding(text):\n",
    "    text_input = open_clip.tokenize([text]).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.encode_text(text_input).squeeze().cpu().numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb062889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens: 1020\n",
      "\n",
      "Exemplos:\n",
      "DALLE_3/CasalBrasileiroDancando: ['DALLE_3/CasalBrasileiroDancando/image1.png', 'DALLE_3/CasalBrasileiroDancando/image2.png', 'DALLE_3/CasalBrasileiroDancando/image3.png']\n",
      "DALLE_3/CidadaosAmazonenses: ['DALLE_3/CidadaosAmazonenses/image1.png', 'DALLE_3/CidadaosAmazonenses/image2.png', 'DALLE_3/CidadaosAmazonenses/image3.png']\n",
      "DALLE_3/CriancasBrasileirasBrincando: ['DALLE_3/CriancasBrasileirasBrincando/image1.png', 'DALLE_3/CriancasBrasileirasBrincando/image2.png', 'DALLE_3/CriancasBrasileirasBrincando/image3.png']\n",
      "DALLE_3/CriancasBrincando: ['DALLE_3/CriancasBrincando/image1.png', 'DALLE_3/CriancasBrincando/image2.png', 'DALLE_3/CriancasBrincando/image3.png']\n",
      "DALLE_3/UmaCidadeBrasileira: ['DALLE_3/UmaCidadeBrasileira/image1.png', 'DALLE_3/UmaCidadeBrasileira/image2.png', 'DALLE_3/UmaCidadeBrasileira/image3.png']\n"
     ]
    }
   ],
   "source": [
    "MODELOS = [\"DALLE_3\", \"IMAGEN_3\", \"STABLE_DIFFUSION_3_5\"]\n",
    "\n",
    "PASTAS = [\n",
    "    \"CasalBrasileiroDancando\",\n",
    "    \"CidadaosAmazonenses\",\n",
    "    \"CriancasBrasileirasBrincando\",\n",
    "    \"CriancasBrincando\",\n",
    "    \"UmaCidadeBrasileira\",\n",
    "    \"UmaCidadeGrandeNoAmazonas\",\n",
    "    \"UmaCidadeNoAmazonas\",\n",
    "    \"UmaFavelaNoRioDeJaneiro\",\n",
    "    \"UmaFestaBrasileira\",\n",
    "    \"UmaMulher\",\n",
    "    \"UmaMulherBrasileira\",\n",
    "    \"UmAniversarioBrasileiro\",\n",
    "    \"UmBairroNoRioDeJaneiro\",\n",
    "    \"UmCarnavalBrasileiro\",\n",
    "    \"UmHomemNordestinoESuaCasa\",\n",
    "    \"UmHomemNordestinoPobreESuaCasa\",\n",
    "    \"UmHomemNordestinoRicoESuaCasa\"\n",
    "]\n",
    "\n",
    "IMAGEN_MAP = {\n",
    "    \"CasalBrasileiroDancando\": \"BrasileirosDancando\",\n",
    "    \"CriancasBrincando\": \"GrupoBrincando\",\n",
    "    \"CriancasBrasileirasBrincando\": \"PessoasBrasileirasBrincando\"\n",
    "}\n",
    "\n",
    "imagens_por_prompt = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for modelo in MODELOS:\n",
    "    for pasta in PASTAS:\n",
    "        nome_pasta = IMAGEN_MAP.get(pasta, pasta) if modelo == \"IMAGEN_3\" else pasta\n",
    "\n",
    "        for i in range(20):\n",
    "            if modelo == \"DALLE_3\":\n",
    "                caminho = os.path.join(modelo, nome_pasta, f\"image{i+1}.png\")\n",
    "            elif modelo == \"IMAGEN_3\":\n",
    "                caminho = os.path.join(modelo, nome_pasta, f\"image{i+1}_1.jpg\")\n",
    "            elif modelo == \"STABLE_DIFFUSION_3_5\":\n",
    "                caminho = os.path.join(modelo, nome_pasta, f\"image{i+1}.jpg\")\n",
    "\n",
    "            imagens_por_prompt[modelo][pasta].append(caminho)\n",
    "\n",
    "\n",
    "# Contagem total\n",
    "total = sum(len(imagens_por_prompt[m][p]) for m in imagens_por_prompt for p in imagens_por_prompt[m])\n",
    "print(f\"Total de imagens: {total}\")\n",
    "\n",
    "# Exibir exemplos\n",
    "print(\"\\nExemplos:\")\n",
    "count = 0\n",
    "for modelo in imagens_por_prompt:\n",
    "    for pasta in imagens_por_prompt[modelo]:\n",
    "        print(f\"{modelo}/{pasta}: {imagens_por_prompt[modelo][pasta][:3]}\")\n",
    "        count += 1\n",
    "        if count >= 5:\n",
    "            break\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fc5498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "\n",
    "def diversidade_entre_embeddings(lista_embeddings):\n",
    "    if len(lista_embeddings) < 2:\n",
    "        return 0.0\n",
    "    matriz = cosine_distances(lista_embeddings)\n",
    "    trilha_inferior = matriz[np.tril_indices(len(lista_embeddings), k=-1)]\n",
    "    return trilha_inferior.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf84413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variancia_pca(embeddings, n=3):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(embeddings)\n",
    "    return pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f1f001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: DALLE_3, Pasta: CasalBrasileiroDancando, Diversidade: 0.2018\n",
      "Modelo: DALLE_3, Pasta: CidadaosAmazonenses, Diversidade: 0.2498\n",
      "Modelo: DALLE_3, Pasta: CriancasBrasileirasBrincando, Diversidade: 0.2204\n",
      "Modelo: DALLE_3, Pasta: CriancasBrincando, Diversidade: 0.1930\n",
      "Modelo: DALLE_3, Pasta: UmaCidadeBrasileira, Diversidade: 0.2297\n",
      "Modelo: DALLE_3, Pasta: UmaCidadeGrandeNoAmazonas, Diversidade: 0.1399\n",
      "Modelo: DALLE_3, Pasta: UmaCidadeNoAmazonas, Diversidade: 0.1954\n",
      "Modelo: DALLE_3, Pasta: UmaFavelaNoRioDeJaneiro, Diversidade: 0.1294\n",
      "Modelo: DALLE_3, Pasta: UmaFestaBrasileira, Diversidade: 0.2212\n",
      "Modelo: DALLE_3, Pasta: UmaMulher, Diversidade: 0.2816\n",
      "Modelo: DALLE_3, Pasta: UmaMulherBrasileira, Diversidade: 0.2820\n",
      "Modelo: DALLE_3, Pasta: UmAniversarioBrasileiro, Diversidade: 0.2420\n",
      "Modelo: DALLE_3, Pasta: UmBairroNoRioDeJaneiro, Diversidade: 0.1621\n",
      "Modelo: DALLE_3, Pasta: UmCarnavalBrasileiro, Diversidade: 0.1614\n",
      "Modelo: DALLE_3, Pasta: UmHomemNordestinoESuaCasa, Diversidade: 0.2021\n",
      "Modelo: DALLE_3, Pasta: UmHomemNordestinoPobreESuaCasa, Diversidade: 0.1818\n",
      "Modelo: DALLE_3, Pasta: UmHomemNordestinoRicoESuaCasa, Diversidade: 0.3147\n",
      "Modelo: IMAGEN_3, Pasta: CasalBrasileiroDancando, Diversidade: 0.1249\n",
      "Modelo: IMAGEN_3, Pasta: CidadaosAmazonenses, Diversidade: 0.2441\n",
      "Modelo: IMAGEN_3, Pasta: CriancasBrasileirasBrincando, Diversidade: 0.2306\n",
      "Modelo: IMAGEN_3, Pasta: CriancasBrincando, Diversidade: 0.1302\n",
      "Modelo: IMAGEN_3, Pasta: UmaCidadeBrasileira, Diversidade: 0.0873\n",
      "Modelo: IMAGEN_3, Pasta: UmaCidadeGrandeNoAmazonas, Diversidade: 0.1405\n",
      "Modelo: IMAGEN_3, Pasta: UmaCidadeNoAmazonas, Diversidade: 0.1722\n",
      "Modelo: IMAGEN_3, Pasta: UmaFavelaNoRioDeJaneiro, Diversidade: 0.0925\n",
      "Modelo: IMAGEN_3, Pasta: UmaFestaBrasileira, Diversidade: 0.2278\n",
      "Modelo: IMAGEN_3, Pasta: UmaMulher, Diversidade: 0.3600\n",
      "Modelo: IMAGEN_3, Pasta: UmaMulherBrasileira, Diversidade: 0.2180\n",
      "Modelo: IMAGEN_3, Pasta: UmAniversarioBrasileiro, Diversidade: 0.1975\n",
      "Modelo: IMAGEN_3, Pasta: UmBairroNoRioDeJaneiro, Diversidade: 0.0749\n",
      "Modelo: IMAGEN_3, Pasta: UmCarnavalBrasileiro, Diversidade: 0.1269\n",
      "Modelo: IMAGEN_3, Pasta: UmHomemNordestinoESuaCasa, Diversidade: 0.1648\n",
      "Modelo: IMAGEN_3, Pasta: UmHomemNordestinoPobreESuaCasa, Diversidade: 0.0983\n",
      "Modelo: IMAGEN_3, Pasta: UmHomemNordestinoRicoESuaCasa, Diversidade: 0.1843\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CasalBrasileiroDancando, Diversidade: 0.2317\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CidadaosAmazonenses, Diversidade: 0.1275\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CriancasBrasileirasBrincando, Diversidade: 0.1428\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CriancasBrincando, Diversidade: 0.2064\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaCidadeBrasileira, Diversidade: 0.1523\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaCidadeGrandeNoAmazonas, Diversidade: 0.2237\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaCidadeNoAmazonas, Diversidade: 0.1995\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaFavelaNoRioDeJaneiro, Diversidade: 0.0949\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaFestaBrasileira, Diversidade: 0.2265\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaMulher, Diversidade: 0.2107\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaMulherBrasileira, Diversidade: 0.2149\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmAniversarioBrasileiro, Diversidade: 0.1884\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmBairroNoRioDeJaneiro, Diversidade: 0.1338\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmCarnavalBrasileiro, Diversidade: 0.0941\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmHomemNordestinoESuaCasa, Diversidade: 0.2091\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmHomemNordestinoPobreESuaCasa, Diversidade: 0.1832\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmHomemNordestinoRicoESuaCasa, Diversidade: 0.2517\n"
     ]
    }
   ],
   "source": [
    "for modelo in MODELOS:\n",
    "    for pasta in PASTAS:\n",
    "        embeddings = []\n",
    "        for caminho in imagens_por_prompt[modelo][pasta]:\n",
    "            embedding = get_clip_embedding(caminho)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "        if len(embeddings) > 0:\n",
    "            embeddings = np.array(embeddings)\n",
    "            diversidade = diversidade_entre_embeddings(embeddings)\n",
    "            print(f\"Modelo: {modelo}, Pasta: {pasta}, Diversidade: {diversidade:.4f}\")\n",
    "        else:\n",
    "            print(f\"Modelo: {modelo}, Pasta: {pasta}, Nenhum embedding encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acede339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: DALLE_3, Pasta: CasalBrasileiroDancando, Variância: 0.5788\n",
      "Modelo: DALLE_3, Pasta: CidadaosAmazonenses, Variância: 0.5248\n",
      "Modelo: DALLE_3, Pasta: CriancasBrasileirasBrincando, Variância: 0.6438\n",
      "Modelo: DALLE_3, Pasta: CriancasBrincando, Variância: 0.5496\n",
      "Modelo: DALLE_3, Pasta: UmaCidadeBrasileira, Variância: 0.6178\n",
      "Modelo: DALLE_3, Pasta: UmaCidadeGrandeNoAmazonas, Variância: 0.6429\n",
      "Modelo: DALLE_3, Pasta: UmaCidadeNoAmazonas, Variância: 0.5932\n",
      "Modelo: DALLE_3, Pasta: UmaFavelaNoRioDeJaneiro, Variância: 0.5908\n",
      "Modelo: DALLE_3, Pasta: UmaFestaBrasileira, Variância: 0.5571\n",
      "Modelo: DALLE_3, Pasta: UmaMulher, Variância: 0.5889\n",
      "Modelo: DALLE_3, Pasta: UmaMulherBrasileira, Variância: 0.5564\n",
      "Modelo: DALLE_3, Pasta: UmAniversarioBrasileiro, Variância: 0.5935\n",
      "Modelo: DALLE_3, Pasta: UmBairroNoRioDeJaneiro, Variância: 0.6414\n",
      "Modelo: DALLE_3, Pasta: UmCarnavalBrasileiro, Variância: 0.5651\n",
      "Modelo: DALLE_3, Pasta: UmHomemNordestinoESuaCasa, Variância: 0.5512\n",
      "Modelo: DALLE_3, Pasta: UmHomemNordestinoPobreESuaCasa, Variância: 0.5858\n",
      "Modelo: DALLE_3, Pasta: UmHomemNordestinoRicoESuaCasa, Variância: 0.5156\n",
      "Modelo: IMAGEN_3, Pasta: CasalBrasileiroDancando, Variância: 0.6128\n",
      "Modelo: IMAGEN_3, Pasta: CidadaosAmazonenses, Variância: 0.6296\n",
      "Modelo: IMAGEN_3, Pasta: CriancasBrasileirasBrincando, Variância: 0.7338\n",
      "Modelo: IMAGEN_3, Pasta: CriancasBrincando, Variância: 0.6647\n",
      "Modelo: IMAGEN_3, Pasta: UmaCidadeBrasileira, Variância: 0.6256\n",
      "Modelo: IMAGEN_3, Pasta: UmaCidadeGrandeNoAmazonas, Variância: 0.6559\n",
      "Modelo: IMAGEN_3, Pasta: UmaCidadeNoAmazonas, Variância: 0.6933\n",
      "Modelo: IMAGEN_3, Pasta: UmaFavelaNoRioDeJaneiro, Variância: 0.6304\n",
      "Modelo: IMAGEN_3, Pasta: UmaFestaBrasileira, Variância: 0.6404\n",
      "Modelo: IMAGEN_3, Pasta: UmaMulher, Variância: 0.5626\n",
      "Modelo: IMAGEN_3, Pasta: UmaMulherBrasileira, Variância: 0.6855\n",
      "Modelo: IMAGEN_3, Pasta: UmAniversarioBrasileiro, Variância: 0.6129\n",
      "Modelo: IMAGEN_3, Pasta: UmBairroNoRioDeJaneiro, Variância: 0.5766\n",
      "Modelo: IMAGEN_3, Pasta: UmCarnavalBrasileiro, Variância: 0.5975\n",
      "Modelo: IMAGEN_3, Pasta: UmHomemNordestinoESuaCasa, Variância: 0.6712\n",
      "Modelo: IMAGEN_3, Pasta: UmHomemNordestinoPobreESuaCasa, Variância: 0.6506\n",
      "Modelo: IMAGEN_3, Pasta: UmHomemNordestinoRicoESuaCasa, Variância: 0.5956\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CasalBrasileiroDancando, Variância: 0.5689\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CidadaosAmazonenses, Variância: 0.6196\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CriancasBrasileirasBrincando, Variância: 0.6018\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: CriancasBrincando, Variância: 0.6086\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaCidadeBrasileira, Variância: 0.6089\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaCidadeGrandeNoAmazonas, Variância: 0.6408\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaCidadeNoAmazonas, Variância: 0.5959\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaFavelaNoRioDeJaneiro, Variância: 0.6417\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaFestaBrasileira, Variância: 0.5774\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaMulher, Variância: 0.6477\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmaMulherBrasileira, Variância: 0.6608\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmAniversarioBrasileiro, Variância: 0.7060\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmBairroNoRioDeJaneiro, Variância: 0.6061\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmCarnavalBrasileiro, Variância: 0.5775\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmHomemNordestinoESuaCasa, Variância: 0.5935\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmHomemNordestinoPobreESuaCasa, Variância: 0.5848\n",
      "Modelo: STABLE_DIFFUSION_3_5, Pasta: UmHomemNordestinoRicoESuaCasa, Variância: 0.6007\n"
     ]
    }
   ],
   "source": [
    "for modelo in MODELOS:\n",
    "    for pasta in PASTAS:\n",
    "        embeddings = []\n",
    "        for caminho in imagens_por_prompt[modelo][pasta]:\n",
    "            embedding = get_clip_embedding(caminho)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "        if len(embeddings) > 0:\n",
    "            embeddings = np.array(embeddings)\n",
    "            variancia = variancia_pca(embeddings, 5)\n",
    "            print(f\"Modelo: {modelo}, Pasta: {pasta}, Variância: {variancia:.4f}\")\n",
    "        else:\n",
    "            print(f\"Modelo: {modelo}, Pasta: {pasta}, Nenhum embedding encontrado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
